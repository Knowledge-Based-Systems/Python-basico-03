{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de ejecutar esta línea de código, explorar el archivo a través de un editor de texto\n",
    "# leer el archivo json, a través de read_json\n",
    "\n",
    "datos1 = pd.read_json(\"data2/instituciones_7.json\")\n",
    "datos2 = pd.read_json(\"data2/instituciones_11.json\")\n",
    "datos3 = pd.read_json(\"data2/instituciones_19.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la línea de código\n",
    "print(datos1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la línea de código\n",
    "print(datos2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la línea de código\n",
    "\n",
    "print(datos3.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analice las salidas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la siguiente línea de código\n",
    "lista_dataframes = [datos1, datos2, datos3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar la función concat de pandas, \n",
    "# el objetivo es unir los dataframes (datos1, datos2 y datos3) en un solo dataframe\n",
    "dataframe_final = pd.concat(lista_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un archivo .json que contenga únicamente las características:\n",
    "# Nombre_Institucion\n",
    "# Provincia \n",
    "# Sostenimiento\n",
    "# Jornada\n",
    "\n",
    "# El archivo debe tener el nombre: instituciones_0003.json, en la carpeta data2\n",
    "\n",
    "# usa la función .to_json\n",
    "# Ejemplo: \n",
    "# datos.to_json(\"data/instituciones.json\", indent=4, orient=\"records\")\n",
    "# Donde, datos es un dataframe, \n",
    "#        data/instituciones.json, es la ruta y el nombre del archivo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
